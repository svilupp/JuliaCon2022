var documenterSearchIndex = {"docs":
[{"location":"resources/#Resources","page":"Resources","title":"Resources","text":"","category":"section"},{"location":"resources/#Various-Introductory-texts","page":"Resources","title":"Various Introductory texts","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"Marketing Mix Modeling (MMM) – Concepts and Model Interpretation\nLight introduction to Adstock from FastCompany","category":"page"},{"location":"resources/#Industry","page":"Resources","title":"Industry","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"Google:\nBayesian Methods for Media Mix Modeling with Carryover and Shape effects\nChallenges and opportunities in Media Mix Modelling\nA Numpyro-based package Lightweight MMM\nMeta/Facebook:\n!!CROWN JEWEL!! Robyn Package from Facebook Research team (experimental). Be careful when using the Weibull transformations (it might be fixed now). A related tutorial\nHello Fresh: Tutorial for Python with PyMC3 here","category":"page"},{"location":"resources/#Frequentist-MMM","page":"Resources","title":"Frequentist MMM","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"MMM in Python with Statsmodels here\nMMM in Python with ScikitLearn here The author has a full series on the topic - recommended!\nMMM in R here","category":"page"},{"location":"resources/#Probabilistic-MMM","page":"Resources","title":"Probabilistic MMM","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"MMM with Stan (a multiplicative model) here and here\nMMM package with CLI and configs here\nSimple MMM in PyMC here\nMMM in Python with PyMC3 here Same author as some articles above - he has a full series.\nPyMC Labs post on MMM and also Learning Bayesian Stats podcast / MMM episode\nOrbit / Bayesian Time-Varying Coefficient Regression / BTVC here, package Orbit-ml\nPython tutorial with PyMC3 (and comparison with Robyn) here\nTime-varying saturation coefficients with PyMC3 here\nOrbit / KTR model","category":"page"},{"location":"resources/#Other-/-On-Transformations-on-the-Input-Variables","page":"Resources","title":"Other / On Transformations on the Input Variables","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"Weibull transformation case study (for Adstock) and here","category":"page"},{"location":"resources/#Other-/-Attribution","page":"Resources","title":"Other / Attribution","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"Survey attribution in Numpyro here\nAttribution models here\nChannelattribution package in R\nEva Anderl, Ingo Becker, Florian v. Wangenheim, Jan H. Schumann (2014)","category":"page"},{"location":"api_reference/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api_reference/#Index","page":"API Reference","title":"Index","text":"","category":"section"},{"location":"api_reference/","page":"API Reference","title":"API Reference","text":"","category":"page"},{"location":"api_reference/","page":"API Reference","title":"API Reference","text":"## Docstrings","category":"page"},{"location":"api_reference/","page":"API Reference","title":"API Reference","text":"Modules = [MediaMixModellingDemo]","category":"page"},{"location":"api_reference/#MediaMixModellingDemo.ParamsPlot","page":"API Reference","title":"MediaMixModellingDemo.ParamsPlot","text":"struct ParamsPlot\n    title_suffix = \"\"\n    color_spend = palette(:default)[6]\n    color_spend_optimized = palette(:default)[6]\n    color_revenues = palette(:default)[1]\n    color_revenues_original = palette(:default)[2]\n    units_revenues = \"USD\"\n    units_spend = \"USD\"\n    title_fontsize = 10\n    table_fontsize_header = 10\n    table_fontsize_body = 8\n    output_dpi = 150\n    output_size_mmm = (1000, 800)\n    output_size_optim = (1000, 800)\nend\n\nHolds plotting defaults\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#MediaMixModellingDemo.ParamsStage1","page":"API Reference","title":"MediaMixModellingDemo.ParamsStage1","text":"struct ParamsStage1\n    model_name=Val(:any)\n    scales_trend_offset::Float64=0.\n    scales_growth_trend::Float64=1.\n    scales_trend::Float64 = 0.2\n    scales_hols::Float64 = 0.3\n    scales_seas::AbstractArray{Float64} = ones(Float64,1)\n    scales_feat::AbstractArray{Float64} = ones(Float64,1)\n    scales_noise::Float64 = 0.2\n    cat_levels::Int = 1\nend\n\nHolds priors and relevant parameters for Stage 1 of the modelling\n\nArguments:\n\nmodel_name=Val(:any) : Symbol representing the model version being fitted\nscales_trend_offset::Float64=0. : Scale (\"width\") of the Normal RV alpha (intercepts for different groups)\nscales_growth_trend::Float64=1. : Scale (\"width\") of the Normal RV growth_trend (trend component)\nscales_trend::Float64 = 0.2 : Scale (\"width\") of the Normal RV beta_trend for input X_trend (flexible trend fitting, eg, with splines)\nscales_hols::Float64 = 0.3 : Scale (\"width\") of the Normal RV beta_hols for input X_hols (holidays features)\nscales_seas::AbstractArray{Float64} = ones(Float64,1) : Scale (\"width\") of the Normal RV beta_seas for input X_feat (seasonality components)\nscales_feat::AbstractArray{Float64} = ones(Float64,1) : Scale (\"width\") of the Normal RV beta_feat for input X_feat (concatenated features)\nscales_noise::Float64 = 0.2 : Extent of the random noise around deterministic trend / rate parameter of Exponential distribution for sigma\ncat_levels::Int = 1 : Number of categorical levels in RV alpha that will be provided in X_cat vector (allows for different intercepts for different groups)\n\nExample:\n\nSet priors with automated priors like this:\n\np1=ParamsStage1(\n    model_name=Val(Symbol(MODEL_NAME_PREFIT)),\n    scales_trend=0.2,\n    scales_hols=0.3,\n    scales_noise=0.2,\n    cat_levels=1\n)\np1=set_priors_stage1_trendline(y_std,p1)\np1=set_priors_auto_scales(y_std,X_seas,:scales_seas,1.0,p1)\np1=set_priors_auto_scales(y_std,X_feat,:scales_feat,1.0,p1)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#MediaMixModellingDemo.ParamsStage2","page":"API Reference","title":"MediaMixModellingDemo.ParamsStage2","text":"struct ParamsStage2\n    model_name=Val(:any)\n    scales_trend_offset::Float64 = 0.3\n    scales_trend::Float64 = 0.2\n    scales_noise::Float64 = 0.3\n    scales_context::AbstractArray{Float64} = ones(Float64,1)\n    scales_org::AbstractArray{Float64} = ones(Float64,1)\n\n    decay_rate_alphas::AbstractArray{Float64} = ones(Float64,1)\n    decay_rate_betas::AbstractArray{Float64} = ones(Float64,1)\n\n    adspend_mean_nonzero::AbstractArray{Float64} = ones(Float64,1)\n    adspend_median::AbstractArray{Float64} = ones(Float64,1)\n\n    locs_spend_halfmaxpoint::AbstractArray{Float64} = ones(Float64,1)\n    scales_spend_halfmaxpoint::AbstractArray{Float64} = ones(Float64,1)\n\n    locs_spend_beta::AbstractArray{Float64} = ones(Float64,1)\n    scales_spend_beta::AbstractArray{Float64} = ones(Float64,1)\n    units_ratio_spend_to_y::AbstractArray{Float64} = ones(Float64,1)\n    factor_to_roas_of_one::AbstractArray{Float64} = units_ratio_spend_to_y .* 2\nend\n\nHolds priors and relevant parameters for Stage 2 of the modelling\n\nFor easy set up, use utility functions that build it from the inputs\n\nArguments:\n\nmodel_name=Val(:any) : Symbol representing the model version being fitted\nscales_trend_offset::Float64=0. : Scale (\"width\") of the Normal RV alpha (intercepts for different groups)\nscales_trend::Float64 = 0.2 : Scale (\"width\") of the Normal RV beta_trend for input X_trend (flexible trend fitting, eg, with splines)\nscales_noise::Float64 = 0.2 : Extent of the random noise around deterministic trend / rate parameter of Exponential distribution for sigma\nscales_context::AbstractArray{Float64} = ones(Float64,1) : Scale (\"width\") of the Normal RV beta_context for input X_context (context variables)\nscales_org::AbstractArray{Float64} = ones(Float64,1) : Scale (\"width\") of the Normal RV beta_org for input X_feat (organic variables - can have only POSITIVE effect)\ndecay_rate_alphas::AbstractArray{Float64} = ones(Float64,1) : decay_rate RV is modelled by Beta distribution, alpha is the corresponding parameter\ndecay_rate_betas::AbstractArray{Float64} = ones(Float64,1) :  decay_rate RV is modelled by Beta distribution, beta is the corresponding parameter\nadspend_mean_nonzero::AbstractArray{Float64} = ones(Float64,1) : Calculated quantity of the average non-zero spend (used to initialize halfmaxpoint)\nadspend_median::AbstractArray{Float64} = ones(Float64,1) : Calculated quantity of median of the spend\nlocs_spend_halfmaxpoint::AbstractArray{Float64} = ones(Float64,1) : Center of the Normal RV halfmaxpoint for the halfmax concentration point in Hill Curve (can be initiated by average of the non-zero spend)\nscales_spend_halfmaxpoint::AbstractArray{Float64} = ones(Float64,1) :  Scale (\"width\") of the Normal RV halfmaxpoint for the halfmax concentration point in Hill Curve\nlocs_spend_beta::AbstractArray{Float64} = ones(Float64,1) : Center of the Normal RV 'beta_spend' that represents the ROAS when the ad spend is at halfmaxpoint\nscales_spend_beta::AbstractArray{Float64} = ones(Float64,1) : Scale (\"width\") of the Normal RV 'beta_spend' that represents the ROAS when the ad spend is at halfmaxpoint\nunits_ratio_spend_to_y::AbstractArray{Float64} = ones(Float64,1) : Ratio of ad spend to Y to be able to convert unit effect (used for factor_to_roas_of_one)\nfactor_to_roas_of_one::AbstractArray{Float64} : Conversion factor that ensures that provided beta_spend represents the ROAS when the ad spend is at halfmaxpoint\n\nExample:\n\np2=ParamsStage2(\n    model_name=Val(Symbol(MODEL_NAME)),\n    scales_trend_offset=0.3,\n    scales_trend=0.2,\n    scales_noise=0.3,\n)\n\np2 = set_priors_auto_scales(y_std,X_context,:scales_context,1.0,p2)\np2 = set_priors_auto_scales(y_std,X_org,:scales_org,1.0,p2)\np2 = set_priors_stage2_hill_curves(X_spend,p2;\n        units_ratio_spend_to_y=getindex.(pipe_cache_spend,:xh)/pipe_cache_y[1].xh,\n        halfmaxpoint_scale=0.3,expected_roas=1.0, expected_roas_scale=1.5)\np2 = set_priors_stage2_decay_rates([\"ooh\",\"digital\",\"digital\",\"ooh\",\"ooh\"],decay_rates_types_dictionary,p2,cols_spend)\n\nsanity_check_priors(p2;X_spend,X_context,X_org);\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#MediaMixModellingDemo.build_inputs-Tuple{AbstractDataFrame}","page":"API Reference","title":"MediaMixModellingDemo.build_inputs","text":"build_inputs(df::AbstractDataFrame;\n    cols_spend::AbstractVector{String},\n    col_target::String=\"revenue\",\n    col_datetime::String=\"dt\",\n    col_time_std::String=\"time_std\",\n    col_cat::String=\"\",\n    cols_hols::AbstractVector{String}=String[],\n    cols_context::AbstractVector{String}=String[],\n    cols_organic::AbstractVector{String}=String[],\n    seasonality_periods::AbstractVector{Float64}=Float64[],\n    spline_degree::Int=0,\n    fit_stage2_mask::AbstractVector{Bool}=trues(nrow(df)),\n    optim_mask::AbstractVector{Bool}=trues(nrow(df))\n)\n\nBuilds the input data object for the successing fitting & optimization\n\nArguments:\n\ncol_target::String=\"revenue\" - column name of the target/response variable (eg, revenues)\ncol_datetime::String=\"dt\" - column name of the variable with dates\ncol_time_std::String=\"time_std\" - column name of the standardized time index (from 0-1, strict)\ncol_cat::String=\"events\" - column name of the categorical variable representing various events (ie not available); Set to \"\" if there isn't any\ncols_context::AbstractVector{String}=String[] - column name of the context variables (eg, macroeconomic indicators, market trends, competitors sales or promotions) (variables will be standardized via Z-score); Defaults to empty if there are none\ncols_organic::AbstractVector{String}=String[] - column name of the organic marketing activities (eg, email newsletters) (variables will be scaled to maximum=1 via Max() function and their effect on response can be only positive); Defaults to empty if there are none\ncols_hols::AbstractVector{String}=String[] - column name of the holiday indicators; Defaults to empty if there are none\ncols_spend::AbstractVector{String} - column names of the Ad spend variables that we want to model (variables will be scaled to maximum=1 via Max() function)\nseasonality_periods::AbstractVector{Float64}=Float64[] - what seasonalities are expected in the trendline; Defaults to empty if there are none\nspline_degree::Int=0 - if complicated trend modelling is needed, what degree of spline basis should be used (uses cubic bases splines from Splines2.jl)\nfit_stage2_mask::AbstractVector{Bool}=trues(nrow(df)) - mask to be apllied to observed data in Stage 2 of modelling (use the observation when =true); Defaults to all observations being used\noptim_mask::AbstractVector{Bool}=trues(nrow(df)) - mask to be apllied in the budget optimization (use the observation when =true); Defaults to all observations being used\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.calc_mroas-Tuple{Number, Number, AbstractMCMC.AbstractChains, Any, Int64}","page":"API Reference","title":"MediaMixModellingDemo.calc_mroas","text":"calc_mroas(x::Number, delta::Number, chain::AbstractMCMC.AbstractChains, p, slice_idx::Int)\n\nCalculate marginal ROAS (mROAS) at a given point x with a delta (=step size) for a variable under slice_idx  (ie, 3rd channel would have slice_idx=3)\n\nExample: Calculate mROAS for all Ad spend variables with delta=0.01\n\n# p2=ParamsStage2() # model parameters from stage 2\n# chain is the result of fitting of stage 2 model\n# cols_spend are ad spend column names\nmroas_at_mean=[calc_mroas(p2.adspend_mean_nonzero[idx],0.01,chain,p2,idx)[1] for idx in 1:length(cols_spend)]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.calc_roas","page":"API Reference","title":"MediaMixModellingDemo.calc_roas","text":"calc_roas(effect::Number, spend::Number, factor_spend_to_effect::Number=1)\n\nCalculates ROAS with an option to normalize the effect to the right scale (if Y and X are scaled)\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.calc_roas-NTuple{4, AbstractArray}","page":"API Reference","title":"MediaMixModellingDemo.calc_roas","text":"calc_roas(effects::AbstractArray, spends::AbstractArray, factors_spend_to_effect::AbstractArray,weights::AbstractArray)\n\nCalculates Total ROAS (of all Ad channels) as a weighted-average of individual ROAS' weighted by the raw spend\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.convert_budget_multiplier_to_spend_multiplier-Tuple{AbstractVector, AbstractVector, AbstractVector}","page":"API Reference","title":"MediaMixModellingDemo.convert_budget_multiplier_to_spend_multiplier","text":"convert_budget_multiplier_to_spend_multiplier(spend_prev_trf::AbstractVector,\n                                                   factor_to_scale_spend_to_orig::AbstractVector,\n                                                   budget_multiplier::AbstractVector)\n\nConverts a relative budget_multiplier (a vector of %s for each marketing channel, eg,  [1,1.2,0.8])  to a spend_multiplier (=output), which retains the total amount of spend in the original domain  Ie, money money between channel while not changing the total spend\n\nExample:\n\nspend_prev_trf=X_spend|>Matrix|>sum_columns|>vec\nfactor_to_scale_spend_to_orig=getindex.(pipe_cache_spend,:xh)\nbudget_multiplier=ones(size(X_spend,2))\nspend_multiplier=convert_budget_multiplier_to_spend_multiplier(spend_prev_trf,factor_to_scale_spend_to_orig,budget_multiplier)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.fit","page":"API Reference","title":"MediaMixModellingDemo.fit","text":"fit(inputs::InputData,fitted_stage1::Stage1Fit,params::ParamsStage2,model_func::Function,\n    algorithm::Turing.Inference.AdaptiveHamiltonian=NUTS(300,0.65;max_depth=10);\n    mcmc_samples=250,mcmc_chains=4)\n\nFits Stage 2 model (marketing transformations of interest) based on model (model_func) with provided data (inputs) and priors (params) fitted_stage1 is a Fit from Stage 1 that holds the trend components (see Documentation for the rationale behind 2-stage fit) Defaults to NUTS algorithm\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.fit-2","page":"API Reference","title":"MediaMixModellingDemo.fit","text":"fit(inputs::InputData,params::ParamsStage1,model_func::Function,\n    algorithm::Turing.Inference.AdaptiveHamiltonian=NUTS(300,0.65;max_depth=10);\n    mcmc_samples=100,mcmc_chains=1)\n\nFits Stage 1 model (trend components) based on model (model_func) with provided data (inputs) and priors (params) Defaults to NUTS algorithm\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.generate_fourier_series","page":"API Reference","title":"MediaMixModellingDemo.generate_fourier_series","text":"generate_fourier_series(t, p=365.25, n=5)\n\nGenerates fourier series with period p and degree n (the higher, the more flexible it is) It can be then fitted with coefficients to mimic any period trend\n\nExpects t to be a time index series\n\nReturns array of shape: (size(t,1),2n)\n\nExample:\n\nseasonality_generate_fourier_series(1:400,365.25, 5)\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.generate_objective_func","page":"API Reference","title":"MediaMixModellingDemo.generate_objective_func","text":"generate_objective_func(\n    chain_optim::AbstractMCMC.AbstractChains,\n        model_orig::DynamicPPL.Model,\n    X_spend::AbstractMatrix, optim_mask::BitVector,\n    spend_raw_sum::AbstractVector,\n    loss_func::Function = identity;\n    simulations_basecase = nothing,\n    extract_key::Symbol=:y)\n\nObjective function generator which runs directly off a budget_multiplier operating on the ad spend in original domain  and producing uplift in terms of revenues (or a chosen extract_key) Auxilary objective (gx) minimizes the delta between original adspend and new adspend (it must be strictly smaller or equal)\n\nNotes:\n\nThis version leaves ad spend budget balancing to the optimization algorithm\nThe simplest loss_func function that you can use is identity!\n\nOptional: simulation_basecase can be provided to speed up the optimization (ie, avoid re-computing the revenue under the old budget)\n\nIf optim_mask subsets data (ie, !=trues(size(Xspend,1))) then only the underlying segment of the `Xspend` matrix is changed  and only that portion of simulated revenues is considered for objective function\n\nExample:\n\n# Prepare inputs\nchain_optim=Chains(chain,:parameters)\nsimulations_prev=simulate_revenues_summed(chain_optim,model_orig,optim_mask;extract_key=:mu)\n\n# boundaries on possible solution\nlower_bound = 0.5*ones(length(cols_spend)) # max 50% reduction\nupper_bound = 1.5*ones(length(cols_spend)) # max 50% increase\nbounds = [lower_bound upper_bound]'\n\n# Bayesian Decision Theory -- how to weigh the outcomes across the posterior distribution\n# define a simple asymmetric (risk-averse) loss function\nloss_func(x)=x>0 ? 0.5x : x\n\n# All channels must have some spend in the optimization period!\n@assert all((@view(X_spend[optim_mask,:])|>sum_columns) .>0)\n\n# Method with direct budget multiplier\n# spend_raw_sum is masked with optim_mask!\nspend_raw_sum=revert_pipe_spend(X_spend[optim_mask,:])|>sum_columns\n\nobjective_func=generate_objective_func(\n    chain_optim,model_orig,Matrix(X_spend),optim_mask,\n    spend_raw_sum,loss_func;simulations_basecase=simulations_prev,extract_key=:mu)\n\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.generate_objective_func-Tuple{AbstractMCMC.AbstractChains, DynamicPPL.Model, AbstractMatrix, BitVector, AbstractVector, Function, AbstractVecOrMat}","page":"API Reference","title":"MediaMixModellingDemo.generate_objective_func","text":"generate_objective_func(chain_optim::AbstractMCMC.AbstractChains,\nmodel_orig::DynamicPPL.Model,\nX_spend::AbstractMatrix, optim_mask::BitVector,\nfactor_to_scale_spend_to_orig::AbstractVector,\nloss_func::Function,\nbounds::AbstractVecOrMat;\nsimulations_basecase = nothing,\nextract_key::Symbol=:y)\n\nGenerates objective function that depends only on budget_multiplier input and returns simulated revenues and other requirements of Metaheuristics Checks that implied spend_multiplier_new (calculated from budget_multiplier) is within the provided bounds as auxilary objective\n\nNotes:\n\nThis version is suitable if optimization algorithm struggles to find solutions that maintain the same adspend (it balances it under the hood)\nThe simplest loss_func function that you can use is identity!\n\nOptional: simulation_basecase can be provided to speed up the optimization (ie, avoid re-computing the revenue under the old budget)\n\nIf optim_mask subsets data (ie, !=trues(size(Xspend,1))) then only the underlying segment of the `Xspend` matrix is changed  and only that portion of simulated revenues is considered for objective function\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.generate_seasonality_features-Tuple{Any, Any}","page":"API Reference","title":"MediaMixModellingDemo.generate_seasonality_features","text":"generate_seasonality_features(t, p=365.25, n=5)\n\nGenerates seasonality features given an array of tuples in a format (period,degree) Eg, 7-day period of degree 3 would be\n\nExpects t to be a time index series\n\nReturns array of shape: (size(t,1),2n)\n\nExample:\n\nseasonality_=generate_fourier_series(1:400,365.25, 5)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.geometric_decay-Union{Tuple{T}, Tuple{AbstractVecOrMat{T}, Any}, Tuple{AbstractVecOrMat{T}, Any, Any}} where T<:Real","page":"API Reference","title":"MediaMixModellingDemo.geometric_decay","text":"geometric_decay(x::Vector{T},decay_rate,normalize=true) where {T<:Real}\n\nSimple geometric decay transformation if normalize=true it divides the output by the sum of the geometric series Note: Does NOT check if decay_rate<1 etc to ensure that the sum convergences to the analytic formula\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.getflatsamples-Tuple{Any, Any}","page":"API Reference","title":"MediaMixModellingDemo.getflatsamples","text":"getflatsamples(chain,groupname)\n\nExtract a group of variables under name groupname from chain  and flattens all samples into the first dimension  ie, outputs a dimension: (numsamples*numchains,num_variables)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.hill_curve-Tuple{Any, Any, Any, Val{:safe}}","page":"API Reference","title":"MediaMixModellingDemo.hill_curve","text":"hill_curve(x, half_max_concentration_point, hill_coef,::Val{:safe})\n\nHill Curve-based spend saturation. Safe implementation that works better with ForwardDiff\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.hill_curve-Tuple{Any, Any, Any}","page":"API Reference","title":"MediaMixModellingDemo.hill_curve","text":"hill_curve(x, half_max_concentration_point, hill_coef)\n\nHill Curve-based spend saturation based on: https://www.physiologyweb.com/calculators/hillequationinteractive_graph.html\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.mean_fitted_effects-Tuple{Val{:model_stage2a}, Any}","page":"API Reference","title":"MediaMixModellingDemo.mean_fitted_effects","text":"extract_fitted_effects(::Val{:model_stage2a},generated_quant,\n    extract_keys=[:mu_trend,:mu_org,:mu_context,:mu_spend_by_var],mask=nothing)\n\nExtract specific keys from the generated_quantities produced by Turing generated_quantities() and concatenates them It should be implemented for each model to ensure the right logic\n\nReturns: a Vector (!)\n\nExample: mean_fitted_effects(Val(:model_stage2a),stage2_fit_allsamples) mean_fitted_effects(Val(:model_stage2a),stage2_fit_allsamples;extract_keys=[:mu_spend_by_var])\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.multiply_and_normalize-Tuple{AbstractVector, AbstractVector}","page":"API Reference","title":"MediaMixModellingDemo.multiply_and_normalize","text":"multiply_and_normalize(v::AbstractVector, multipliers::AbstractVector)\n\nMultiplies a vector v (of adspend) by multipliers in a way that doesn't change the overall sum\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.optimize-Tuple{Stage2Fit, InputData}","page":"API Reference","title":"MediaMixModellingDemo.optimize","text":"optimize(fitted::Stage2Fit, inputs::InputData;\n              metaheuristics_options::Metaheuristics.Options = nothing,\n              multiplier_bounds = nothing)\n\nRuns optimization loop and returns results in the struct OptimalBudget\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.plot_contributions-Tuple{Any, Any, Any}","page":"API Reference","title":"MediaMixModellingDemo.plot_contributions","text":"plot_contributions(effect_shares, cols, p)\n\nCreates a waterfall plot to show % contributions to fitted revenues (no-noise! only deterministic components)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.plot_effects_vs_spend-NTuple{4, Any}","page":"API Reference","title":"MediaMixModellingDemo.plot_effects_vs_spend","text":"plot_effects_vs_spend(effect_shares, spend_shares, cols, p)\n\nPlots a comparison between where we spend money (spend_shares) vs effect on revenues (effect_shares). Expressed in relative terms (% of total)\n\nBig differences within each category (spend % vs effect %) suggest optimization opportunities\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.plot_mmm_one_pager-Tuple{Any, Int64, Any}","page":"API Reference","title":"MediaMixModellingDemo.plot_mmm_one_pager","text":"plot_mmm_one_pager(plot_array, frame_idx::Int64, p)\n\nCombines all plots in plot array into 1 layout for MMM 1-pager\n\nAllows to reveal the plots partially, one by one (provide frame_idx)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.plot_model_fit_by_period-Tuple{Any, Any, Any}","page":"API Reference","title":"MediaMixModellingDemo.plot_model_fit_by_period","text":"plot_model_fit_by_period(y_true, y_pred, p)\n\nCreate a plot comparing the modelled revenues(y_pred) vs actuals (y_true)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.plot_optimization_one_pager-Tuple{Any, Int64, Any}","page":"API Reference","title":"MediaMixModellingDemo.plot_optimization_one_pager","text":"plot_optimization_one_pager(plot_array, frame_idx::Int64, p)\n\nCreate a layout for Optimization 1-pager given a provided array of plots (plot_array)\n\nIt is possible to reveal plots one by one (use frame_idx)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.plot_optimized_contribution-NTuple{7, Any}","page":"API Reference","title":"MediaMixModellingDemo.plot_optimized_contribution","text":"plot_optimized_contribution(effect_prev, effect_optim, roas_total, optim_start,\n                                 optim_end, revert_y_func, p)\n\nPlots expected delta in revenue if the new marketing budget has been implemented (on the same period)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.plot_optimized_spend_share_comparison-NTuple{4, Any}","page":"API Reference","title":"MediaMixModellingDemo.plot_optimized_spend_share_comparison","text":"plot_optimized_spend_share_comparison(spend_share_prev, spend_share_optim, cols, p)\n\nPlots a comparison between previous marketing spend allocation and the optimum discovered\n\nNote that the differences are constrainted by the optimization settings (see multiplier_bounds !)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.plot_optimized_uplift_histogram-Tuple{Any, Any}","page":"API Reference","title":"MediaMixModellingDemo.plot_optimized_uplift_histogram","text":"plot_optimized_uplift_histogram(revenue_uplift, p)\n\nPlots a histogram of modelled uplift (revenue_uplift)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.plot_periodogram","page":"API Reference","title":"MediaMixModellingDemo.plot_periodogram","text":"function plot_periodogram(input_arr,top_k)\n\nPlot Fourier transform coefficients to uncover the most prominent frequencies / seasonalities Assumes equally spaced data points Looks only for periods that have seen at least 2 full cycles (ie, size ÷ 2 at maximum!) Shows top-k values\n\nExample\n\np=10 # period is 10\ny=sin.(2π/p*collect(1:20)) # generate 20 data points\nplot_periodogram(y,1) # plot periodogram, period=10 should be highlighted as maximum\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.plot_priors_decay_rate","page":"API Reference","title":"MediaMixModellingDemo.plot_priors_decay_rate","text":"plot_priors_decay_rate(p,cols=nothing)\n\nPlots priors for decay rate in terms of Beta distributions\n\nExample:\n\np2=ParamsStage2()\ncols_spend=nothing # available from data prep\nplot_priors_decay_rate(p2,cols_spend)\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.plot_response_curves_table-NTuple{6, Any}","page":"API Reference","title":"MediaMixModellingDemo.plot_response_curves_table","text":"plot_response_curves_table(decay_rates, roass, mroas_at_means, cols, roas_total, p)\n\nPlot a quick summary table of the parameters of the response curves\n\nExpects vectors of parameters - one of each channel\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.quick_nuts_diagnostics-Tuple{AbstractMCMC.AbstractChains, Int64}","page":"API Reference","title":"MediaMixModellingDemo.quick_nuts_diagnostics","text":"quick_nuts_diagnostics(chain::AbstractMCMC.AbstractChains, max_depth::Int)\n\nPrints quick diagnostics of NUTS algorithm - mostly importantly alerting the user if there have been any divergences\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.saturate_adspend-Tuple{Number, AbstractMCMC.AbstractChains, AbstractVector}","page":"API Reference","title":"MediaMixModellingDemo.saturate_adspend","text":"saturate_adspend(x::Number, chain::AbstractMCMC.AbstractChains, factor_to_roas_of_one::AbstractVector)\n\nExtracts Hill Curve parameters and the corresponding beta coefficients from provided chain  and applies them to a provided point (x)\n\nWARNING: Depends on model implementation using the same RVs as modelstage2a, ie, `betaspend,halfmaxpoint,slope`\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.set_priors-Tuple{ParamsStage1, InputData}","page":"API Reference","title":"MediaMixModellingDemo.set_priors","text":"set_priors(params::ParamsStage1,inputs::InputData)\n\nSets automated priors based on input data for Stage 1 fitting\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.set_priors-Tuple{ParamsStage2, InputData}","page":"API Reference","title":"MediaMixModellingDemo.set_priors","text":"set_priors(params::ParamsStage2,inputs::InputData)\n\nSets automated priors based on input data for Stage 2 fitting\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.set_priors_auto_scales","page":"API Reference","title":"MediaMixModellingDemo.set_priors_auto_scales","text":"set_priors_auto_scales(y::AbstractArray,X,param_key::Symbol,factor::Union{Number,AbstractArray}=1.0,\n    existing_params=ParamsStage1())\n\nSets scales such that 1 standard dev of input data (X) could trigger at most 3standard dev. response of Y (y)  (because beta coefficient are Normal). This can be increased by factor (defaults to 1.0x). Result is saved into a Parameters object (as per constructor) under a key param_key It can extend (selectively update) existing set of parameters (provide to argument existing_params)\n\nSpecial behaviour:\n\nValues are clipped to range 0.05 - 10. (warning will be issued if it's exceeded)\nShortcuts to straight passthrough if X=nothing\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.set_priors_stage2_decay_rates","page":"API Reference","title":"MediaMixModellingDemo.set_priors_stage2_decay_rates","text":"set_priors_stage2_decay_rates(decay_rate_types::AbstractArray{String},\n    decay_rates_types_dictionary::Dict=decay_rates_types_dictionary,\n    existing_params=ParamsStage2(),var_names=nothing)\n\nSets decay rates priors (for Beta distribution) as a dictionary lookup  of different options available in decay_rates_types_dictionary (eg, \"tv\", \"digital\")\n\nExample:\n\ntypes_=[\"ooh\",\"digital\",\"digital\",\"ooh\",\"ooh\"]\nset_priors_stage2_decay_rates(types_,decay_rates_types_dictionary,p2,cols_spend)\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.simulate_revenues_summed-Tuple{AbstractMCMC.AbstractChains, DynamicPPL.Model, BitVector}","page":"API Reference","title":"MediaMixModellingDemo.simulate_revenues_summed","text":"simulate_revenues_summed(chain_optim::AbstractMCMC.AbstractChains, model_optim::DynamicPPL.Model,\n\noptimmask::BitVector;extractkey::Symbol=:y)\n\nSamples posterior predictive from model model_optim conditioned on Chains chain_optim. Optional - you can provide a mask optim_mask (for time dimensions/1st dimension) and Symbol for the posterior predictive value (extract_key)\n\nExample:\n\nsimulations_prev=simulate_revenues_summed(chain_optim,model_orig,optim_mask;extract_key=:y)\n\nFor budget simulations we replace inputs in the model like:\n\nchain_optim=Chains(chain,:parameters)\nmodel_args_prev=model_orig.args;\n# replace the old spend with new\nmodel_args_new=merge(model_args_prev,(;X_spend=X_spend_new));\nsimulations=simulate_revenues_summed(chain_optim,model_stage2a(model_args_new...),optim_mask);\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.standardize_by_max-Tuple{Any}","page":"API Reference","title":"MediaMixModellingDemo.standardize_by_max","text":"standardize_by_max(X)\n\nMax()-only transform to allow easy scaling between features and the outcome Uses MinMax() pipe under the hood but overwrites the minimum to be =0\n\nExample:\n\ny_std,pipe_cache_y=standardize_by_max(select(df,target_label))\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.standardize_by_zscore-Tuple{Any}","page":"API Reference","title":"MediaMixModellingDemo.standardize_by_zscore","text":"standardize_by_zscore(X)\n\nZscore transform to center the feature to its mean value and scale it (to make it easier to set priors)\n\nExample:\n\ny_std,pipe_cache_y=standardize_by_zscore(select(df,target_label))\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.sum_columns-Tuple{AbstractMatrix}","page":"API Reference","title":"MediaMixModellingDemo.sum_columns","text":"sum_columns(x::AbstractMatrix)\n\nUnified interface that sums columns of a provided Matrix/DataFrame/Vector Returns a Vector (!)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.threaded_objective_func-Tuple{Any, Any}","page":"API Reference","title":"MediaMixModellingDemo.threaded_objective_func","text":"threaded_objective_func(budget_multipliers,objective_func)\n\nParallelizes provided function objective_func for Metaheuristics optimization loop  by leveraging available threads in your Julia instance\n\nExample:\n\nMake sure to change the keyword to parallel_evaluation=true\n\noptions = Metaheuristics.Options(time_limit=10.,debug=false,parallel_evaluation=true)\n@time result = Metaheuristics.optimize(x->threaded_objective_func(x,objective_func), bounds,\n    Metaheuristics.ECA(N=7*2*length(cols_spend),K=7,η_max=2.,options=options))\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#MediaMixModellingDemo.to_masked_matrix","page":"API Reference","title":"MediaMixModellingDemo.to_masked_matrix","text":"to_masked_matrix(x::DataFrame,mask=trues(size(x,1)))\n\nConverts DataFrame to a matrix and applies a mask to its rows if provided\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#MediaMixModellingDemo.workflow_budget_to_simulation-Tuple{AbstractMCMC.AbstractChains, DynamicPPL.Model, AbstractMatrix, BitVector, AbstractVector, AbstractVector}","page":"API Reference","title":"MediaMixModellingDemo.workflow_budget_to_simulation","text":"workflow_budget_to_simulation(\n                chain_optim::AbstractMCMC.AbstractChains, model_orig::DynamicPPL.Model,\n               X_spend::AbstractMatrix, optim_mask::BitVector,\n               factor_to_scale_spend_to_orig::AbstractVector,\n               budget_multiplier::AbstractVector)\n\nFor a given context (budget_multiplier) produces new adspend (X_spend_new) and associated simulated revenues (smulations_new) Used to produced an objective function for the optimization that depends only on budget_multiplier\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RecipesBase.plot","page":"API Reference","title":"RecipesBase.plot","text":"Plots.plot(optimal::OptimalBudget, fitted::Stage2Fit, inputs::InputData,\n                pplot::ParamsPlot = ParamsPlot())\n\nWraps all computations required to plot the Optimization 1-pager\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#RecipesBase.plot-2","page":"API Reference","title":"RecipesBase.plot","text":"Plots.plot(fitted::Stage2Fit, inputs::InputData, pplot::ParamsPlot = ParamsPlot())\n\nWraps all computations to create MMM 1-Pager\n\n\n\n\n\n","category":"function"},{"location":"practical_tips/#Practical-Tips","page":"Practical Tips","title":"Practical Tips","text":"","category":"section"},{"location":"practical_tips/#Getting-Started","page":"Practical Tips","title":"Getting Started","text":"","category":"section"},{"location":"practical_tips/","page":"Practical Tips","title":"Practical Tips","text":"As the first step, read through the Robyn package documentation","category":"page"},{"location":"practical_tips/#Frequently-Asked-Questions","page":"Practical Tips","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"practical_tips/","page":"Practical Tips","title":"Practical Tips","text":"To be updated...","category":"page"},{"location":"practical_tips/","page":"Practical Tips","title":"Practical Tips","text":"\"I still don't understand the concept of Adstock\" \nRead the following article on Adstock\nHow to set priors for Ad spend variables\n(Robyn documentation, section on Adstock and Diminishing returns](https://facebookexperimental.github.io/Robyn/docs/features) provides some rules of thumb\nDecay rate priors (implicitly defined via half-life ranges) are also mentioned on Wikipedia, however, they imply quite a long-lasting effect. Always ask the experts if it's realistic for your business/type of campaign/position in the funnel!\nFor beta_spend coefficients use either a conservative range (eg, centered around 1 and from 0 to 5) or leverage data from previous experiments / from experts\nTo help you with the process, there are several utility functions (see the Demo notebooks)\nHow to set priors for all else\nTalk to the subject matter experts in your business on what a realistic range of values would be (on the overall modelled quantity / for the implied dynamic). If it's hard to judge, ask them for what values would be impossible, which gives you edges for your prior distributions. If possible, ask them to also give you a sense of how quite the likelihood of different values goes up or down within the range (a good exercise is to ask them to stack PET bottle caps or post-it note packs to represent the relative likelihoods of different values)\nOnce you know some boundary values and the relative shape, play with plot() and various distributions to achieve the desired fit, eg, plot(Beta(10,10)) and visually inspect if it matches the provided knowledge (bounds, mass, center, skew, etc.)\nWhy the two-stage fit\nWhile it's not always necessary, it's a really good default that should work well in most cases (there are some implications, see the Discussion in section Methodology)\nIf we were fitting all variables at once, we are likely to get even bigger uncertainties across all RVs because the trendline is fitted as well. That is why we 'cut feedback' between the first and second stage of modelling","category":"page"},{"location":"practical_tips/","page":"Practical Tips","title":"Practical Tips","text":"What to do when the fitting goes bad     - If you're having problems with the inference (eg, divergences - see the bullet below What are some good diagnostics)     - If you're getting bad results, check that your data is correct and appropriately standardized (plots + describe) and that it is not a result of your priors (eg, loosen your assumptions). It that still doesn't work, try to run your model with the generated data - it's a super helpful tool for debugging     - In general, there is an excellent paper on Bayesian workflow","category":"page"},{"location":"practical_tips/","page":"Practical Tips","title":"Practical Tips","text":"What are some good diagnostics\nThe best resource: Bayesian workflow\nRhat metric should never be above 1.1, ideally close to 1.0 for the parameters that we care about\n(HMC/NUTS specific) No divergences. Divergences indicate that the algorithm was not able to fully explore the posterior distribution. There is a folk theorem that it's usually due to a bad model - investigate pair plots, variables with low rhat or with low n_eff and try to re-parameterize where possible. You can read more in Stan Manual\nIf the problem is small (a few divergences), it can be resolved by increasing target_acceptance to 0.9 / 0.99, but please note that it only makes the steps smaller, it does not solve the underlying problem if there is some degeneracy in your posterior!\nIf NUTS diagnostics reports that you have a lot of trajectories that exceeded the maximum tree depth, consider increasing it to 12/14. Except that your inference will slow down significantly.\nPosterior predictive checks - Generate some data from your fitted model. Its distribution should overlap with the observed data.\nOther diagnostics include traceplots, rankplots, loo-psis, prior predictive checks, etc. \nIf you want to compare different models/implementations, use Pareto-smoothed Leave-one-out score (PSIS-LOO, use packages: Arviz.jl or ParetoSmooth.jl)\nWhy does optimization take so long","category":"page"},{"location":"practical_tips/","page":"Practical Tips","title":"Practical Tips","text":"- Our objective function is not convex, so we cannot use any gradient-based methods\n- Instead, we use Metaheuristics package and we provide it with a fixed \"budget\" of time to try to find the optimum (set to 60 seconds in the Demo notebook)\n- Ideally, you want to make sure to run at least D * 1000 evaluations, where `D=number of Adspend variables` (authors of ECA algorithm that we use in the Demo recommend running D * 10000 evaluations)\n- In terms of speed per evaluation, the objective function calls `generated_quantities` in Turing each time with new inputs (proposed new Ad spend):\n    - Make sure you're not re-computing the base case scenario (original Ad spend)\n    - If your model is relatively straightforward (like the demo), you can re-write it as a deterministic function of the posterior samples (expected speed up could be even 2-3x per evaluation)\n\t- If your dataset is large but you care about only a small period (eg, the past few months), you can apply a mask to data provided to the Turing model (Note: Be careful not to lose some of the lagged effects/ramp-up time. Make sure to masked ALL datasets consistently)","category":"page"},{"location":"practical_tips/","page":"Practical Tips","title":"Practical Tips","text":"How to extend / more advanced implementations\nFirst, try the data-centric approach\nAre there more internal datasets you can add? More detail? \nAny external datasets? (eg, macroeconomic data, market trackers and trends, competitive intelligence)\nDifferent inference routine (easy with Turing.jl!), eg, Variation Inference in Turing (ELBO!), ZigZag, or simply a MAP","category":"page"},{"location":"practical_tips/","page":"Practical Tips","title":"Practical Tips","text":"- Apply inference tricks, eg, re-parametrization of the distributions but also the functions you use\n- Change the observational model (eg, add fatter tails if you data demands it - examples provided in the `model_definitions` file)\n- Add more dependencies/prior knowledge, eg, correlation, sparsity (Regularized Horse Shoe prior works well), tighter priors\n- Add more flexible relationships and trends, eg, multiplicative model, saturating growth trend, spline-based trends (example provided in the Demo)\n- Different marketing variable transformations, eg, decay models based on Weibull PDF or CDF, piece-wise linear, flip the order of decaying vs saturation (especially if the spend is in rare and large lumps!)","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"EditURL = \"<unknown>/1-demo-high-level.jl\"","category":"page"},{"location":"demo-high-level/#JuliaCon-MMM-Demo","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Example application of Media Mix Modelling to optimize marketing spend","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"High-level workflow:","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Input and transform data\nProvide column names of the corresponding to groups of variables (eg, cols_spend for Adspend variables to be modelled)\nVariables that can have positive-only effects will be standardized to 0-1 range\nVariables with any-signed effects will be at least standardized via Z-Score\nSet priors / conversion factors\nIe, use your domain knowledge to set realistic marketing transforms' parameters\nStage 1: Fit the trend\nExtract separate series for growth trend, seasonality, holidays, organic variables\nStage 2: Fit the coefficients for marketing transformation\nValidate the fit (Rhat, traceplots, etc)\nQuantify the contributions + ROAS of the current marketing spend\nOptimize the marketing budget to maximize the marketing contribution\nDefine a loss function that reflects your business' decision-making process\nEvaluate the results of the optimization + inherent uncertainty","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"For more details on the methodology and practical tips visit MMM Demo Docs","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"using Pkg; Pkg.activate(\".\");\n\nimport Optim\nimport Metaheuristics\n\nusing Logging\n#### Optional: disable logging\n# disable_logging(Logging.Info);\nimport DisplayAs\n\nusing MediaMixModellingDemo\n# MMMDemo reexports: Turing,DataFramesMeta,Distributions,TableTransforms,Plots,StatsPlots\n\n# Optional for better display:\nENV[\"LINES\"]=200\nENV[\"COLUMNS\"]=600\nThreads.nthreads();\nnothing #hide","category":"page"},{"location":"demo-high-level/#Generate","page":"JuliaCon - MMM Demo","title":"Generate","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Let's generate some example data where we know \"truth\", so we can test this implementation","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"You can see the \"truth\" if you have logging enabled for level INFO","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Y,X,col_names=create_dataset(\"2020-02-01\",105,0);\n\n# Let's apply standard notation of df being the source of data\ndf=X\ndf[!,:revenue]=vec(sum.(eachrow(Y)));\n\nimg=plot(df.revenue)\nimg=DisplayAs.PNG(img) # trick for Literate.jl","category":"page"},{"location":"demo-high-level/#Modelling","page":"JuliaCon - MMM Demo","title":"Modelling","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"We will fit the model in 2 stages to deal with the under-specification.","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"As a convention the deterministic location of the observed variable (mean of the RV y) will be called mu and its components will be all prefixed as such, eg,","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"mu_trend for the trend component,\nmu_seas for the seasonality component,\nmu_hols for the holidays component,\nmu_context for the contributions of the contextual variables,\nmu_org\nmu_spend for the contribution of all Ad spend variables together\nmu_spend_by_var for the contributions of each individual spend variables (ie, number of columns = number of Ad spend variables)","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"(See src/model_definition.jl for more details)","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"All these deterministic components will be exposed by DynamicPPL in the return statement to be easily extracted via generated_quantities() conditioned on fitted samples (a chains object). In other words, given a model fit, we can easily extract all the above components by playing the samples through the model.","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Let's choose what model implementation we want:","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"# Model used in stage1\nconst MODEL_NAME_PREFIT=\"model_stage1a\"\nmodel_func_stage1=getfield(MediaMixModellingDemo,Symbol(MODEL_NAME_PREFIT))\n\n# Model used in stage2\nconst MODEL_NAME=\"model_stage2a\"\nmodel_func_stage2=getfield(MediaMixModellingDemo,Symbol(MODEL_NAME))\n\n# Modifier of chart titles\nconst EXPERIMENT_NAME=\" JuliaCon\"\npplot=ParamsPlot(title_suffix=EXPERIMENT_NAME)\n;\nnothing #hide","category":"page"},{"location":"demo-high-level/#Data","page":"JuliaCon - MMM Demo","title":"Data","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Let's identify seasonalities in our data (for trend modelling)","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Pick the ones with the highest value (usually only 1 or 2 max)","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"# what's the seasonality\nimg=plot_periodogram(df.revenue .- mean(df.revenue),3)\nimg=DisplayAs.PNG(img) # trick for Literate.jl","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Let's build our input data object:","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"@doc build_inputs","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"inputs=build_inputs(df;\n    col_target=\"revenue\",col_datetime=\"dt\",col_time_std=\"time_std\",col_cat=\"events\",\n    cols_context=[c for c in col_names.cols_context if c!=\"newsletters\"],\n    cols_organic=[\"newsletters\"],\n    cols_hols=[\"hols_ind\"],\n    cols_spend=col_names.cols_spend,\n    seasonality_periods=[4.],\n    spline_degree=0\n);\nnothing #hide","category":"page"},{"location":"demo-high-level/#Stage-1-Prophet-like-model","page":"JuliaCon - MMM Demo","title":"Stage 1 - Prophet-like model","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Let's fit a model to the trend, seasonality and holidays","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Note: We do not adstock/saturate the marketing spend at this stage","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"p1=set_priors(\n    ParamsStage1(\n        model_name=Val(Symbol(MODEL_NAME_PREFIT)),\n        scales_trend=0.2,\n        scales_hols=0.3,\n        scales_noise=0.2,\n        cat_levels=1\n    ),\n    inputs\n);\nnothing #hide","category":"page"},{"location":"demo-high-level/#Fit","page":"JuliaCon - MMM Demo","title":"Fit","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"stage1fit=fit(inputs,p1,model_func_stage1,NUTS(300,0.65;max_depth=10));\nnothing #hide","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"# Optional: Check the priors used and if they are sensible\n# y_prior=mapreduce(x->rand(stage1fit.model).y,hcat,1:100)|>vec\n# plot_prior_predictive_histogram(inputs.y_std,y_prior,ParamsPlot())","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"img=plot_model_fit_by_period(inputs.y_std,predict(stage1fit),ParamsPlot())\nimg=DisplayAs.PNG(img) # trick for Literate.jl","category":"page"},{"location":"demo-high-level/#Stage-2-Fit-the-Marketing-Drivers","page":"JuliaCon - MMM Demo","title":"Stage 2 - Fit the Marketing Drivers","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Let's use the fit from the first stage and focus mostly on the marketing variables (including their adstock/saturation transformations)","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"img=plot_model_fit_by_period(inputs.y_std,sum(stage1fit.stage1_fitted_trends,dims=2)|>vec,\n    ParamsPlot(title_suffix=\" for the Trend Components\"))\nimg=DisplayAs.PNG(img) # trick for Literate.jl","category":"page"},{"location":"demo-high-level/#Fit-2","page":"JuliaCon - MMM Demo","title":"Fit","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"p2=set_priors(\n    ParamsStage2(\n        model_name=Val(Symbol(MODEL_NAME)),\n        scales_trend_offset=0.3,\n        scales_trend=0.2,\n        scales_noise=0.3,\n    ),\n    inputs\n);\n# quick check of decay_rate priors\np2 = set_priors_stage2_decay_rates([\"digital\",\"tv\",\"digital\"],decay_rates_types_dictionary,\n    p2,inputs.cols_spend)\n\n# let's check if our priors make sense given te data\nsanity_check_priors(p2;inputs.X_spend,inputs.X_context,inputs.X_org);\n\n# let's visualize the selected decay rates\nimg=plot_priors_decay_rate(p2,inputs.cols_spend)\nimg=DisplayAs.PNG(img) # trick for Literate.jl","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"stage2fit=fit(inputs,stage1fit,p2,model_func_stage2,\n    NUTS(300,0.65;max_depth=10);\n    mcmc_samples=250,mcmc_chains=4);\nnothing #hide","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"# Optional1: Check the priors used and if they are sensible\n# y_prior=mapreduce(x->rand(stage1fit.model).y,hcat,1:100)|>vec\n# plot_prior_predictive_histogram(inputs.y_std,y_prior,ParamsPlot())\n\n## Optional2: Show the posterior samples of quantities of interest\n# stage2fit.chain\n\n## Optional3: Diagnostics if the parameter space has been properly explored\n# corner(chain[[namesingroup(stage2fit.chain,\"slope\")...,\n#             namesingroup(stage2fit.chain,\"decay_rate\")...]],\n#     guidefontsize=8,size=(1000,1000))\n\n# corner(chain[[namesingroup(chain,\"slope\")...,\n# namesingroup(chain,\"beta_spend\")...,Symbol(\"beta_org[1]\")]],\n#     guidefontsize=8,size=(1000,1000))\n\n# Optional4: Diagnostics of the mixing in the chains\n# Display traceplots -- look for \"fuzzy caterpillars\"! Any flat lines (ie, chain getting stuck on some values) indicate problems!\n# plot(chain)","category":"page"},{"location":"demo-high-level/#Evaluation","page":"JuliaCon - MMM Demo","title":"Evaluation","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"img=plot(stage2fit,inputs,pplot)\nimg=DisplayAs.PNG(img) # trick for Literate.jl\n#### optional: save the chart\n# savefig(pl,joinpath(pwd(),\"exports\",\"mmm-1pager-$(pplot.title_suffix).png\"))","category":"page"},{"location":"demo-high-level/#Optimization","page":"JuliaCon - MMM Demo","title":"Optimization","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"Let's optimize the marketing budget, ie, let's find out by what factor should we increase/decrease our spend on each marketing channel/activity without spending more money overall","category":"page"},{"location":"demo-high-level/#Metaheuristics-loop","page":"JuliaCon - MMM Demo","title":"Metaheuristics loop","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"###### Metaheuristics Options (runs ECA algorithm under the hood)\n# time_limit is in seconds\n# debug = true if you want to see each iteration\n# parallel_evaluation = true if you have batch-enabled objective function (see docs for `threaded_objective_func`)\nmetaheuristics_options = Metaheuristics.Options(time_limit=60.,debug=false,parallel_evaluation=true)\noptimalbudget=optimize(stage2fit,inputs;metaheuristics_options);\n\n# quick sanity check\nsanity_check_optimum(optimalbudget,stage2fit,inputs);\nnothing #hide","category":"page"},{"location":"demo-high-level/#Pager","page":"JuliaCon - MMM Demo","title":"1-Pager","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"img=plot(optimalbudget,stage2fit,inputs,pplot)\nimg=DisplayAs.PNG(img) # trick for Literate.jl\n#### optional: save the chart\n# savefig(pl,joinpath(pwd(),\"exports\",\"optimization-1pager-$(pplot.title_suffix).png\"))","category":"page"},{"location":"demo-high-level/#END","page":"JuliaCon - MMM Demo","title":"END","text":"","category":"section"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"","category":"page"},{"location":"demo-high-level/","page":"JuliaCon - MMM Demo","title":"JuliaCon - MMM Demo","text":"This page was generated using Literate.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = MediaMixModellingDemo","category":"page"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is a documentation for MediaMixModellingDemo.","category":"page"},{"location":"","page":"Home","title":"Home","text":"It is an example of the Media Mix Modelling (MMM) analysis produced to acompany a talk at JuliaCon 2022.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For more details please see the Demo notebooks (one with high-level API and one more resembling the actual workflow with Revise).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"index.md\", \"methodology.md\",\"practical_tips.md\",\"resources.md\"]\nDepth = 3","category":"page"},{"location":"methodology/#Methodology","page":"Methodology","title":"Methodology","text":"","category":"section"},{"location":"methodology/#Goals","page":"Methodology","title":"Goals","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"Quantify the benefits of your marketing activities (ROAS, mROAS, etc.)\nRe-allocate marketing spend across different marketing channels/activities to maximize revenues","category":"page"},{"location":"methodology/#Challenges","page":"Methodology","title":"Challenges","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"Insufficient data (eg, unobserved data, untracked data, too little data given the changing dynamics in the market)\nUnderspecified problem / weak identifiability (eg, Hill Curves for Ad spend saturation are \"too flexible\")","category":"page"},{"location":"methodology/#Building-blocks","page":"Methodology","title":"Building blocks","text":"","category":"section"},{"location":"methodology/#Modelling-decisions-to-make-it-work","page":"Methodology","title":"Modelling decisions to make it work","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"Use Bayesian inference, which allows us to capture the uncertainty / underspecification of the key parameters\nSpecify our model with Turing / DynamicPPL, which allows us to apply almost any logic that we can express in Julia / we know from domain expertise\nLeverage structural decomposition of the time series (eg, trend + seasonality + Ad spend + ...)\nFit the model in two stages to reduce the weak identifiability (effectively cutting the feedback of the first stage model on modelling the plain trend)\nReparametrize our model and scale all predictors, which enables us to easily leverage our domain knowledge (and existing experiments) and set informative priors\nOperate on fitted results in MCMCChains, which allows to leverage many algorithms to fit our model, eg, HMC, NUTS, VI, MAP, ZigZag, etc\nApply Bayesian Decision Theory (custom loss function over the samples) to reflect your business’ context, preferences and decision making\nFind the optimal budget with Metaheuristics to overcome that some objectives will be non-convex (ie, there will be local optima)","category":"page"},{"location":"methodology/#Discussion-of-Some-of-the-Implications","page":"Methodology","title":"Discussion of Some of the Implications","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"To make the pre-defined models re-usable, we must enforce certain naming and grouping conventions (eg, all marketing spend variables must be supplied in the same Dataframe, similarly all context variables must be supplied in another Dataframe) and standardization (context variables are standardized by Zscore, but revenues and marketing spend are Max() scaled to allow for easy conversions and setting of priors) - This is less relevant if you're using the high-level API\nMax() scaling of revenues and marketing spend could be a poor choice if there are many outliers in the data (but that would also complicate matters for the auto priors for the Zscore transformed variables as they are loosely linked to standard deviation of the revenues\nReparametrization of the model allows directly setting the expected ROAS at an average ad spend level, but it implicitly assumes that the inflection of the Hill Curve (Halfmax concentration point or halfmaxpoint RV in the model) is at your average level as well (ie, if the channel is relatively underutilized / very low, it might be a too conservative assumption and it could reduce your fitted ROAS)\nThe models might be harder to fit (follow the standard Bayesian workflow and diagnostics - see FAQ for references)\nTwo-stage fit implicitly assumes independence between marketing spend and other variables (eg, holidays would not interact with marketing effects)\nSecond stage fit can be done on a smaller window if all inputs are masked (subset) consistently, but make sure to reflect this masking in plotting the fit results and in the optimization\nOptimization can be run on a smaller window than the fit (optim_mask) but that reduces its potential uplift because there will be a ramp-up/adjustment period to adjust to new spend levels (because of the Geometric Decay) - make sure the optimization window is not too short to see the full effect of more “decayed” variables","category":"page"},{"location":"methodology/#High-level-Workflow","page":"Methodology","title":"High-level Workflow","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"Transform data \nResponse variable (=revenues) to be standardized to 0-1 range (where y=0 implies that revenue=0)\nVariables that can have positive-only effects need to be standardized to 0-1 range (where =0 implies that value=0)\nVariables with any-signed effects need to be at least standardized via Z-Score\nNote: Code expects certain naming conventions (eg, X_spend for the DataFrame of the ad spend variables to be modelled - more on that below)\nSet priors / conversion factors\nScale the priors based on the values of the input data\nLeverage as much context + business knowledge as possible in setting possible parameters for the marketing transforms\nStage 1: Fit the trend\nExtract separate series for growth trend, seasonality, holidays, organic variables \nCreate a new dataset (growth trend, seasonality, holidays) to use as a fixed input in the second stage \nStage 2: Fit the coefficients for marketing transformation\nValidate the fit (Rhat, traceplots, etc)\nValidate the model quality (Pseudo-R2, NRMSE) - we ideally need >80% of the variation to be explained by our model to have meaningful results\nQuantify the contributions + ROAS of the current marketing spend\nProduce model fit summary 1-pager with key plots\nOptimize the marketing budget to maximize the marketing contribution \nDefine a loss function that reflects your business' decision-making process\nProduce optimization summary 1-pager with the results of the optimization + inherent uncertainty","category":"page"},{"location":"methodology/#Naming-Conventions-and-Variables","page":"Methodology","title":"Naming Conventions and Variables","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"Relevant only for the low-level API","category":"page"},{"location":"methodology/#Input-data","page":"Methodology","title":"Input data","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"Codebase depends on variables under the following names:\nX_spend: DataFrame of Ad spend to be transformed (only positive coefficients will be allowed)\nX_org: DataFrame of organic variables (ie, only positive coefficients will be allowed)\nX_cat: 1-column DataFrame with a categorical variable (eg, for events)\nX_hols: DataFrame with holiday events (currently, 1-column with dummy encoding of holiday effect)\nX_context: Any context variables (eg, market drivers, market index, competitor popularity)\nX_seas: Created seasonality DataFrame\nX_feat: horizontal concatenation of Xspend,Xorg,X_content (order does not matter)\nX_trend: Optional - Spline-basis for flexible trend modelling\ny_std: transformed response variable\ny_true: original response variable (=revenues)\ntime_std: transformed time index running from 0-1 during the whole period (important for setting priors)\ndf: series of datetime values corresponding to the observations\ncols_spend: Vector of ad spend variables in the same order as X_spend (ie, names(X_spend))\ncat_levels: Integer of how many levels are in the 1-column DataFrame X_cat\nTransformations caches saved under pipecachey,pipecachespend\npipe_cache_y: TableTransforms cache to revert y-variable transform\npipe_cache_spend: TableTransforms cache to revert X_spend variables transform\nFunctions:\nrevert_pipe_y: utility to revert transformation of y-variable\nrevert_pipe_spend: utility to revert transformation of the ad spend variables","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"Reason: Most of them are used when setting conversion ratios and priors in ParamsStage1 (variable called p1) and ParamsStage2 (variable called p2)","category":"page"},{"location":"methodology/#Turing-Models","page":"Methodology","title":"Turing Models","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"We will fit the model in 2 stages to deal with the under-specification.","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"As a convention the deterministic location of the observed variable (mean of the RV y) will be called mu and its components will be all prefixed as such, eg, ","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"mu_trend for the trend component, \nmu_seas for the seasonality component, \nmu_hols for the holidays component,\nmu_context for the contributions of the contextual variables,\nmu_org\nmu_spend for the contribution of all Ad spend variables together\nmu_spend_by_var for the contributions of each individual spend variable (ie, number of columns = number of Ad spend variables)","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"(See src/model_definition.jl for more details)","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"All these deterministic components will be exposed by DynamicPPL in the return statement to be easily extracted via generated_quantities() conditioned on fitted samples (a chains object). In other words, given a model fit, we can easily extract all the above components by playing the samples through the model.","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"Fitted results from each stage:","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"Stage 1: \nFitted parameters (Chains): chain_stage1\nGenerated quantities (eg, mu_trend etc): stage1_fit\nStage 2:\nModel used for fitting: model_orig\nFitted parameters (Chains): chain\nGenerated quantities (eg, mu_trend etc): stage2_fit_allsamples (or simply stage2fit) ","category":"page"},{"location":"methodology/#Optimization","page":"Methodology","title":"Optimization","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"budget_multiplier_optim holds the recommended multiplier for the X_spend (=Ad spend) that yields the maximum revenue uplift. simulations_optim holds the generated quantities resulting from the above optimal Ad spend.","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"There is an option to run the optimization only on a subset of data using the mask optim_mask.","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"In general, most objects that are derived from this optimal budget are suffixed with _optim (eg, simulations_optim). In contrast, the un-optimized quantities are often suffixed as _prev (eg, spend_share_prev)","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"In addition, if there is a variable that has an original domain (=dollars) and a transformed domain like Ad spend, it will have additional suffix _raw and _trf for the original and transformed domain, respectively, (eg, optimal Ad spend standardized to 0-1 range -> X_spend_optim_trf ). ","category":"page"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"To make the contrast really explicit, if some values are in the original domain, they could have the suffix _raw","category":"page"},{"location":"methodology/#Other","page":"Methodology","title":"Other","text":"","category":"section"},{"location":"methodology/","page":"Methodology","title":"Methodology","text":"For plotting consistency, some of the defaults are saved in struct ParamsPlot","category":"page"}]
}
